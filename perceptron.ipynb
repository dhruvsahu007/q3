# perceptron.ipynb

# --- 1. Import Libraries ---
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# --- 2. Load and Normalize Data ---
data = pd.read_csv("fruit.csv")

X = data[['length_cm', 'weight_g', 'yellow_score']].values
y = data['label'].values.reshape(-1, 1)

# Normalize features
X = (X - X.mean(axis=0)) / X.std(axis=0)

# --- 3. Initialize Weights and Hyperparameters ---
np.random.seed(42)
weights = np.random.randn(X.shape[1], 1)
bias = 0.0
learning_rate = 0.1
epochs = 500

# For tracking
losses = []
accuracies = []

# --- 4. Sigmoid and Loss Function ---
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def compute_loss(y_true, y_pred):
    eps = 1e-10  # to avoid log(0)
    return -np.mean(y_true * np.log(y_pred + eps) + (1 - y_true) * np.log(1 - y_pred + eps))

# --- 5. Training Loop ---
for epoch in range(epochs):
    # Forward pass
    z = np.dot(X, weights) + bias
    y_pred = sigmoid(z)

    # Compute loss and accuracy
    loss = compute_loss(y, y_pred)
    pred_labels = (y_pred >= 0.5).astype(int)
    accuracy = np.mean(pred_labels == y)

    losses.append(loss)
    accuracies.append(accuracy)

    # Backward pass
    dz = y_pred - y
    dw = np.dot(X.T, dz) / X.shape[0]
    db = np.mean(dz)

    # Update weights
    weights -= learning_rate * dw
    bias -= learning_rate * db

    # Early stopping
    if loss < 0.05:
        print(f"Stopping early at epoch {epoch} with loss {loss:.4f}")
        break

# --- 6. Plot Loss and Accuracy ---
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(losses, label='Loss')
plt.title("Loss per Epoch")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(accuracies, label='Accuracy', color='green')
plt.title("Accuracy per Epoch")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.grid(True)

plt.tight_layout()
plt.show()
 
